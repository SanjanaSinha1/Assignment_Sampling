{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726c4fff",
   "metadata": {},
   "source": [
    "## Program should have:\n",
    "\n",
    "-Convert dataset into balanced class data-set.<br> \n",
    "-Create 5 samples (using the sample size detection formula)<br>\n",
    "-Apply 5 different sampling terchniques(S1-S5) on 5 different ML models(M1-M5)<br>\n",
    "-Determine which sampling technique gives acuracy on which model.<br>\n",
    "-Upload solution on the Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8254bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49024eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading csv\n",
    "\n",
    "df= pd.read_csv('Creditcard_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf57c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc84da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f06883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54b3613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can see that data is not balanced.\n",
    "df['Class'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d326b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7fda3f",
   "metadata": {},
   "source": [
    "# Oversampling and Applying K cross Validation\n",
    "\n",
    "duplicate random records from the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787eeafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: (763, 31)\n",
      "class 1: (9, 31)\n"
     ]
    }
   ],
   "source": [
    "#seperating class that will be class 0 and class 1.\n",
    "# class count\n",
    "class_count_0, class_count_1 = df['Class'].value_counts()\n",
    "\n",
    "# Separate class (class_0 and class_1 are new dateframe formed)\n",
    "class_0 = df[df['Class'] == 0]\n",
    "class_1 = df[df['Class'] == 1]# print the shape of the class\n",
    "print('class 0:', class_0.shape)\n",
    "print('class 1:', class_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d668b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>529</td>\n",
       "      <td>-2.000567</td>\n",
       "      <td>-2.495484</td>\n",
       "      <td>2.467149</td>\n",
       "      <td>1.140053</td>\n",
       "      <td>2.462010</td>\n",
       "      <td>0.594262</td>\n",
       "      <td>-2.110183</td>\n",
       "      <td>0.788347</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422452</td>\n",
       "      <td>1.195394</td>\n",
       "      <td>0.297836</td>\n",
       "      <td>-0.857105</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.861019</td>\n",
       "      <td>-0.124622</td>\n",
       "      <td>-0.171060</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>164</td>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.551033</td>\n",
       "      <td>0.451890</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.822947</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.123050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128758</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>0.151012</td>\n",
       "      <td>-1.363967</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>0.075412</td>\n",
       "      <td>0.231750</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>539</td>\n",
       "      <td>-1.738582</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>1.187057</td>\n",
       "      <td>-0.656652</td>\n",
       "      <td>0.920623</td>\n",
       "      <td>-0.291788</td>\n",
       "      <td>0.269083</td>\n",
       "      <td>0.140631</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179545</td>\n",
       "      <td>-0.192036</td>\n",
       "      <td>-0.261879</td>\n",
       "      <td>-0.237477</td>\n",
       "      <td>-0.335040</td>\n",
       "      <td>0.240323</td>\n",
       "      <td>-0.345129</td>\n",
       "      <td>-0.383563</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>472</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   529 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
       "1522   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "1523   164  0.073497  0.551033  0.451890  0.114964  0.822947  0.251480   \n",
       "1524   539 -1.738582  0.052740  1.187057 -0.656652  0.920623 -0.291788   \n",
       "1525   472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521 -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
       "1522  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012   \n",
       "1523  0.296319  0.139497 -0.123050  ... -0.128758 -0.381932  0.151012   \n",
       "1524  0.269083  0.140631  0.023464  ... -0.179545 -0.192036 -0.261879   \n",
       "1525  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "1521 -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50      1  \n",
       "1522 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "1523 -1.363967 -1.389079  0.075412  0.231750  0.230171    0.99      1  \n",
       "1524 -0.237477 -0.335040  0.240323 -0.345129 -0.383563    1.00      1  \n",
       "1525 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming 'target' is your target column and the rest are your features\n",
    "x = df.drop('Class', axis=1) \n",
    "y = df['Class']\n",
    "\n",
    "# Step 1: Oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "x_resampled, y_resampled = oversampler.fit_resample(x, y)\n",
    "\n",
    "# Create a new DataFrame with resampled data\n",
    "df_resampled = pd.concat([pd.DataFrame(x_resampled, columns=x.columns),\n",
    "                          pd.Series(y_resampled, name='Class')], axis=1)\n",
    "\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88f7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x_resampled,y_resampled, test_size=0.4, train_size=0.6, random_state= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18266223",
   "metadata": {},
   "source": [
    "# Creating Samples using Following methods\n",
    "\n",
    " ### 1. Simple Random Sampling \n",
    " ### 2. Systematic Sampling\n",
    " ### 3. Stratified Sampling\n",
    " ### 4. Cluster Sampling\n",
    " ### 5. Bootstrap Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ac133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccf8a4",
   "metadata": {},
   "source": [
    "# 1. Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d20572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "sample_size = 100  # Specify the desired sample size\n",
    "\n",
    "# Create a simple random sample using the sample method in pandas\n",
    "simple_random_sample = df_resampled.sample(n=sample_size, random_state=0)\n",
    "\n",
    "x_simple_random_sample=simple_random_sample.iloc[:,:-1]\n",
    "y_simple_random_sample=simple_random_sample.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(x_simple_random_sample, y_simple_random_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_simple_random_sample, y_simple_random_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_simple_random_sample, y_simple_random_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_simple_random_sample)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(x_simple_random_sample, y_simple_random_sample)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and fit the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(x_simple_random_sample, y_simple_random_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3d528",
   "metadata": {},
   "source": [
    "# 2. Systematic Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the size of your systematic sample (adjust as needed)\n",
    "sample_size = 100  # Specify the desired sample size\n",
    "\n",
    "# Ensure sample_size is not greater than the DataFrame size\n",
    "sample_size = min(sample_size, len(df_resampled))\n",
    "\n",
    "# Calculate the interval for systematic sampling\n",
    "\n",
    "k = max(1, len(df_resampled) // sample_size)\n",
    "End=(len(df_resampled) // sample_size)*sample_size\n",
    "# Choose a random starting point\n",
    "start_index = np.random.randint(0, min(k, len(df_resampled) - 1))\n",
    "\n",
    "# Apply systematic sampling to create a subsample\n",
    "systematic_sample = df_resampled.iloc[start_index:End:k]\n",
    "systematic_sample\n",
    "# Print the systematic subsample\n",
    "# print(systematic_sample)\n",
    "# print(\"k:\", k)\n",
    "# print(\"start_index:\", start_index)\n",
    "x_systematic_sample=systematic_sample.iloc[:,:-1]\n",
    "y_systematic_sample=systematic_sample.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(x_systematic_sample, y_systematic_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_systematic_sample, y_systematic_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_systematic_sample, y_systematic_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_systematic_sample)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(x_systematic_sample, y_systematic_sample)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and fit the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(x_systematic_sample, y_systematic_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aad8f6",
   "metadata": {},
   "source": [
    "# 3. Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming df_balanced is your balanced DataFrame obtained after oversampling\n",
    "\n",
    "# Create features (X) and labels (y)\n",
    "X = df_resampled.drop(columns=['Class'])\n",
    "y = df_resampled['Class']\n",
    "\n",
    "total_sample_size = 100  # Adjust as needed\n",
    "\n",
    "# Set the proportion of the total sample size for training\n",
    "train_proportion = 0.8  # Adjust as needed\n",
    "\n",
    "# Calculate the size of the training set\n",
    "train_size = int(train_proportion * total_sample_size)\n",
    "\n",
    "# Calculate the size of the testing set\n",
    "test_size = total_sample_size - train_size\n",
    "# Create a StratifiedShuffleSplit object for stratified sampling with a limited sample size\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size, test_size=test_size, random_state=42)\n",
    "# Iterate through the stratified sampling\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    # Extract the stratified sample\n",
    "    x_stratified_sample = X.iloc[test_index]\n",
    "    y_stratified_sample = y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(x_stratified_sample, y_stratified_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_stratified_sample, y_stratified_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_stratified_sample, y_stratified_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_stratified_sample)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(x_stratified_sample, y_stratified_sample)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and fit the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(x_stratified_sample,y_stratified_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fcf1f1",
   "metadata": {},
   "source": [
    "# 4. Cluster Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cbfb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "\n",
    "# Assuming df_balanced is your balanced DataFrame obtained after oversampling\n",
    "\n",
    "# Set the number of clusters for K-Means\n",
    "num_clusters = 10\n",
    "\n",
    "# Set the desired sample size\n",
    "sample_size = 100  # Adjust as needed\n",
    "\n",
    "# Extract features (X) from df_balanced\n",
    "X = df_resampled.drop(columns=['Class'])\n",
    "\n",
    "# Initialize the KMeans model with the specified number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, n_init='auto', random_state=42)\n",
    "\n",
    "# Fit the KMeans model to the features and assign cluster labels\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Convert the cluster labels to a Pandas Series\n",
    "clusters = pd.Series(clusters)\n",
    "\n",
    "# Randomly select a subset of cluster indices\n",
    "selected_clusters = random.sample(range(num_clusters), 3)\n",
    "\n",
    "# Initialize a variable to keep track of the total sample size\n",
    "current_sample_size = 0\n",
    "\n",
    "# Initialize an empty DataFrame to store the final sample\n",
    "df_final_sample = pd.DataFrame()\n",
    "\n",
    "# Iterate through selected clusters and include rows in the final sample\n",
    "for cluster_index in selected_clusters:\n",
    "    # Select rows from the original data based on the current cluster\n",
    "    cluster_rows = df_resampled.loc[clusters == cluster_index]\n",
    "    \n",
    "    # Calculate the remaining sample size needed\n",
    "    remaining_sample_size = sample_size - current_sample_size\n",
    "    \n",
    "    # Determine the number of rows to include from the current cluster\n",
    "    rows_to_include = min(remaining_sample_size, len(cluster_rows))\n",
    "    \n",
    "    # Randomly select rows from the current cluster\n",
    "    selected_rows = cluster_rows.sample(n=rows_to_include, random_state=42)\n",
    "    \n",
    "    # Append the selected rows to the final sample\n",
    "    df_final_sample = pd.concat([df_final_sample, selected_rows])\n",
    "    \n",
    "    # Update the total sample size\n",
    "    current_sample_size += len(selected_rows)\n",
    "\n",
    "    # Break the loop if the desired sample size is reached\n",
    "    if current_sample_size >= sample_size:\n",
    "        break\n",
    "\n",
    "# Print the shape of the final sample\n",
    "cluster_sample= df_final_sample\n",
    "# _cluster_sample\n",
    "x_cluster_sample=cluster_sample.iloc[:,:-1]\n",
    "y_cluster_sample=cluster_sample.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbc2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(x_cluster_sample, y_cluster_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_cluster_sample, y_cluster_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_cluster_sample, y_cluster_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_cluster_sample)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(x_cluster_sample, y_cluster_sample)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and fit the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(x_cluster_sample,y_cluster_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a752b7",
   "metadata": {},
   "source": [
    "# 5. Bootstrap Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7d92a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the number of bootstrap samples\n",
    "num_bootstrap_samples = 20  # Adjust as needed\n",
    "\n",
    "# Set the desired sample size\n",
    "desired_sample_size = 5  # Adjust as needed\n",
    "\n",
    "# Initialize an empty DataFrame to store the bootstrap samples\n",
    "bootstrap_samples = pd.DataFrame()\n",
    "\n",
    "# Perform bootstrap sampling\n",
    "for _ in range(num_bootstrap_samples):\n",
    "    # Create a bootstrap sample by randomly sampling with replacement\n",
    "    bootstrap_sample = df_resampled.sample(n=desired_sample_size, replace=True, random_state=2)\n",
    "    \n",
    "    # Append the bootstrap sample to the DataFrame\n",
    "    bootstrap_samples = pd.concat([bootstrap_samples, bootstrap_sample])\n",
    "\n",
    "# Print the shape of the resulting bootstrap samples DataFrame\n",
    "# print(bootstrap_samples.shape)\n",
    "# bootstrap_samples\n",
    "x_bootstrap_sample=bootstrap_samples.iloc[:,:-1]\n",
    "y_bootstrap_sample=bootstrap_samples.iloc[:,-1]\n",
    "# import numpy as np\n",
    "\n",
    "# unique_classes = np.unique(y_bootstrap_sample)\n",
    "# print(\"Unique Classes:\", unique_classes)\n",
    "# class_0 = y_bootstrap_sample[y_bootstrap_sample == 0]# print the shape of the class\n",
    "# print('class 0:', class_0.shape)\n",
    "# class_1 = y_bootstrap_sample[y_bootstrap_sample == 1]\n",
    "# print('class 1:', class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3426f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(x_bootstrap_sample,y_bootstrap_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(x_bootstrap_sample,y_bootstrap_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_bootstrap_sample, y_bootstrap_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for SVM\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_bootstrap_sample)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(x_bootstrap_sample, y_bootstrap_sample)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = svm_model.predict(x_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and fit the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(x_bootstrap_sample, y_bootstrap_sample)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
